----------------------------------------------------------------------------------------------------
18-12-10 23:59:29
SEED = 1544457569
----------------------------------------------------------------------------------------------------
Options are printed as follows:
title = 'DenseNet121'
mode = 'train'  # 'train', 'test', 'restart', 'debug', 'export', 'input_train', 'input_test', 'speed_net'
seed = None
delay = False  # start training after xxx minutes
gpu_list = [0,1,2,3]
batch_size = 256
dataset = 'imagenet'  # 'mnist','svhn','cifar10', 'cifar100', 'imagenet', 'fashion'
preprocess = 'inception'  # 'mnist', 'cifar', 'inception', 'alexnet', 'inception_v2'
network = 'densenet'  # 'mlp', 'lenet', 'alexnet', 'densenet_test', 'resnet_test', 'mobilenet_v1', 'mobilenet_v2', shufflenet_v2
path_load = None
path_save = True   # None, False, True, or specify a dir
l2_decay = {'decay': 1.0e-4, 'exclude': ['depthwise']}
epoch_step = tf.Variable(1, name='epoch_step', trainable=False)
learning_step = tf.Variable(0, name='learning_step', trainable=False)
lr_decay = tf.train.cosine_decay(0.1, epoch_step, decay_steps=100)  # imagenet cosine
loss_func = tf.losses.softmax_cross_entropy
optimizer = tf.train.MomentumOptimizer(lr_decay, 0.9, use_nesterov=True)
----------------------------------------------------------------------------------------------------
Multi-GPU training tower with gpu list [0, 1, 2, 3]
All parameters are pinned to CPU, all Ops are pinned to GPU
Get batchnorm moving average updates from data in the first GPU for speed
Get L2 decay grads in the second GPU for speed
Training model on GPU 0
Perform input channel normalization in GPU for speed
In the inception_v2 argumentation, image are already scaled to [0,1]
mean = [0.485 0.456 0.406] std = [0.229 0.224 0.225]
Input data format is NHWC, convert to NCHW
DenseNet for ImageNet dataset
/device:CPU:0 init/conv_1 [7, 7, 3, 64]
/device:CPU:0 init/BatchNorm/gamma [64]
/device:CPU:0 init/BatchNorm/beta [64]
/device:CPU:0 B0_L0/Bottleneck/conv_1 [1, 1, 64, 128]
/device:CPU:0 B0_L0/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B0_L0/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B0_L0/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B0_L1/BatchNorm/gamma [96]
/device:CPU:0 B0_L1/BatchNorm/beta [96]
/device:CPU:0 B0_L1/Bottleneck/conv_1 [1, 1, 96, 128]
/device:CPU:0 B0_L1/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B0_L1/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B0_L1/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B0_L2/BatchNorm/gamma [128]
/device:CPU:0 B0_L2/BatchNorm/beta [128]
/device:CPU:0 B0_L2/Bottleneck/conv_1 [1, 1, 128, 128]
/device:CPU:0 B0_L2/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B0_L2/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B0_L2/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B0_L3/BatchNorm/gamma [160]
/device:CPU:0 B0_L3/BatchNorm/beta [160]
/device:CPU:0 B0_L3/Bottleneck/conv_1 [1, 1, 160, 128]
/device:CPU:0 B0_L3/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B0_L3/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B0_L3/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B0_L4/BatchNorm/gamma [192]
/device:CPU:0 B0_L4/BatchNorm/beta [192]
/device:CPU:0 B0_L4/Bottleneck/conv_1 [1, 1, 192, 128]
/device:CPU:0 B0_L4/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B0_L4/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B0_L4/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B0_L5/BatchNorm/gamma [224]
/device:CPU:0 B0_L5/BatchNorm/beta [224]
/device:CPU:0 B0_L5/Bottleneck/conv_1 [1, 1, 224, 128]
/device:CPU:0 B0_L5/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B0_L5/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B0_L5/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 T0/BatchNorm/gamma [256]
/device:CPU:0 T0/BatchNorm/beta [256]
/device:CPU:0 T0/conv_1 [1, 1, 256, 128]
/device:CPU:0 B1_L0/BatchNorm/gamma [128]
/device:CPU:0 B1_L0/BatchNorm/beta [128]
/device:CPU:0 B1_L0/Bottleneck/conv_1 [1, 1, 128, 128]
/device:CPU:0 B1_L0/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L0/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L0/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L1/BatchNorm/gamma [160]
/device:CPU:0 B1_L1/BatchNorm/beta [160]
/device:CPU:0 B1_L1/Bottleneck/conv_1 [1, 1, 160, 128]
/device:CPU:0 B1_L1/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L1/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L1/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L2/BatchNorm/gamma [192]
/device:CPU:0 B1_L2/BatchNorm/beta [192]
/device:CPU:0 B1_L2/Bottleneck/conv_1 [1, 1, 192, 128]
/device:CPU:0 B1_L2/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L2/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L2/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L3/BatchNorm/gamma [224]
/device:CPU:0 B1_L3/BatchNorm/beta [224]
/device:CPU:0 B1_L3/Bottleneck/conv_1 [1, 1, 224, 128]
/device:CPU:0 B1_L3/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L3/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L3/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L4/BatchNorm/gamma [256]
/device:CPU:0 B1_L4/BatchNorm/beta [256]
/device:CPU:0 B1_L4/Bottleneck/conv_1 [1, 1, 256, 128]
/device:CPU:0 B1_L4/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L4/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L4/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L5/BatchNorm/gamma [288]
/device:CPU:0 B1_L5/BatchNorm/beta [288]
/device:CPU:0 B1_L5/Bottleneck/conv_1 [1, 1, 288, 128]
/device:CPU:0 B1_L5/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L5/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L5/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L6/BatchNorm/gamma [320]
/device:CPU:0 B1_L6/BatchNorm/beta [320]
/device:CPU:0 B1_L6/Bottleneck/conv_1 [1, 1, 320, 128]
/device:CPU:0 B1_L6/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L6/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L6/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L7/BatchNorm/gamma [352]
/device:CPU:0 B1_L7/BatchNorm/beta [352]
/device:CPU:0 B1_L7/Bottleneck/conv_1 [1, 1, 352, 128]
/device:CPU:0 B1_L7/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L7/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L7/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L8/BatchNorm/gamma [384]
/device:CPU:0 B1_L8/BatchNorm/beta [384]
/device:CPU:0 B1_L8/Bottleneck/conv_1 [1, 1, 384, 128]
/device:CPU:0 B1_L8/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L8/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L8/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L9/BatchNorm/gamma [416]
/device:CPU:0 B1_L9/BatchNorm/beta [416]
/device:CPU:0 B1_L9/Bottleneck/conv_1 [1, 1, 416, 128]
/device:CPU:0 B1_L9/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L9/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L9/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L10/BatchNorm/gamma [448]
/device:CPU:0 B1_L10/BatchNorm/beta [448]
/device:CPU:0 B1_L10/Bottleneck/conv_1 [1, 1, 448, 128]
/device:CPU:0 B1_L10/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L10/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L10/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B1_L11/BatchNorm/gamma [480]
/device:CPU:0 B1_L11/BatchNorm/beta [480]
/device:CPU:0 B1_L11/Bottleneck/conv_1 [1, 1, 480, 128]
/device:CPU:0 B1_L11/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B1_L11/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B1_L11/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 T1/BatchNorm/gamma [512]
/device:CPU:0 T1/BatchNorm/beta [512]
/device:CPU:0 T1/conv_1 [1, 1, 512, 256]
/device:CPU:0 B2_L0/BatchNorm/gamma [256]
/device:CPU:0 B2_L0/BatchNorm/beta [256]
/device:CPU:0 B2_L0/Bottleneck/conv_1 [1, 1, 256, 128]
/device:CPU:0 B2_L0/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L0/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L0/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L1/BatchNorm/gamma [288]
/device:CPU:0 B2_L1/BatchNorm/beta [288]
/device:CPU:0 B2_L1/Bottleneck/conv_1 [1, 1, 288, 128]
/device:CPU:0 B2_L1/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L1/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L1/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L2/BatchNorm/gamma [320]
/device:CPU:0 B2_L2/BatchNorm/beta [320]
/device:CPU:0 B2_L2/Bottleneck/conv_1 [1, 1, 320, 128]
/device:CPU:0 B2_L2/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L2/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L2/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L3/BatchNorm/gamma [352]
/device:CPU:0 B2_L3/BatchNorm/beta [352]
/device:CPU:0 B2_L3/Bottleneck/conv_1 [1, 1, 352, 128]
/device:CPU:0 B2_L3/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L3/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L3/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L4/BatchNorm/gamma [384]
/device:CPU:0 B2_L4/BatchNorm/beta [384]
/device:CPU:0 B2_L4/Bottleneck/conv_1 [1, 1, 384, 128]
/device:CPU:0 B2_L4/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L4/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L4/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L5/BatchNorm/gamma [416]
/device:CPU:0 B2_L5/BatchNorm/beta [416]
/device:CPU:0 B2_L5/Bottleneck/conv_1 [1, 1, 416, 128]
/device:CPU:0 B2_L5/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L5/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L5/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L6/BatchNorm/gamma [448]
/device:CPU:0 B2_L6/BatchNorm/beta [448]
/device:CPU:0 B2_L6/Bottleneck/conv_1 [1, 1, 448, 128]
/device:CPU:0 B2_L6/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L6/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L6/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L7/BatchNorm/gamma [480]
/device:CPU:0 B2_L7/BatchNorm/beta [480]
/device:CPU:0 B2_L7/Bottleneck/conv_1 [1, 1, 480, 128]
/device:CPU:0 B2_L7/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L7/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L7/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L8/BatchNorm/gamma [512]
/device:CPU:0 B2_L8/BatchNorm/beta [512]
/device:CPU:0 B2_L8/Bottleneck/conv_1 [1, 1, 512, 128]
/device:CPU:0 B2_L8/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L8/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L8/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L9/BatchNorm/gamma [544]
/device:CPU:0 B2_L9/BatchNorm/beta [544]
/device:CPU:0 B2_L9/Bottleneck/conv_1 [1, 1, 544, 128]
/device:CPU:0 B2_L9/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L9/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L9/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L10/BatchNorm/gamma [576]
/device:CPU:0 B2_L10/BatchNorm/beta [576]
/device:CPU:0 B2_L10/Bottleneck/conv_1 [1, 1, 576, 128]
/device:CPU:0 B2_L10/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L10/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L10/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L11/BatchNorm/gamma [608]
/device:CPU:0 B2_L11/BatchNorm/beta [608]
/device:CPU:0 B2_L11/Bottleneck/conv_1 [1, 1, 608, 128]
/device:CPU:0 B2_L11/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L11/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L11/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L12/BatchNorm/gamma [640]
/device:CPU:0 B2_L12/BatchNorm/beta [640]
/device:CPU:0 B2_L12/Bottleneck/conv_1 [1, 1, 640, 128]
/device:CPU:0 B2_L12/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L12/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L12/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L13/BatchNorm/gamma [672]
/device:CPU:0 B2_L13/BatchNorm/beta [672]
/device:CPU:0 B2_L13/Bottleneck/conv_1 [1, 1, 672, 128]
/device:CPU:0 B2_L13/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L13/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L13/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L14/BatchNorm/gamma [704]
/device:CPU:0 B2_L14/BatchNorm/beta [704]
/device:CPU:0 B2_L14/Bottleneck/conv_1 [1, 1, 704, 128]
/device:CPU:0 B2_L14/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L14/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L14/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L15/BatchNorm/gamma [736]
/device:CPU:0 B2_L15/BatchNorm/beta [736]
/device:CPU:0 B2_L15/Bottleneck/conv_1 [1, 1, 736, 128]
/device:CPU:0 B2_L15/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L15/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L15/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L16/BatchNorm/gamma [768]
/device:CPU:0 B2_L16/BatchNorm/beta [768]
/device:CPU:0 B2_L16/Bottleneck/conv_1 [1, 1, 768, 128]
/device:CPU:0 B2_L16/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L16/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L16/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L17/BatchNorm/gamma [800]
/device:CPU:0 B2_L17/BatchNorm/beta [800]
/device:CPU:0 B2_L17/Bottleneck/conv_1 [1, 1, 800, 128]
/device:CPU:0 B2_L17/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L17/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L17/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L18/BatchNorm/gamma [832]
/device:CPU:0 B2_L18/BatchNorm/beta [832]
/device:CPU:0 B2_L18/Bottleneck/conv_1 [1, 1, 832, 128]
/device:CPU:0 B2_L18/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L18/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L18/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L19/BatchNorm/gamma [864]
/device:CPU:0 B2_L19/BatchNorm/beta [864]
/device:CPU:0 B2_L19/Bottleneck/conv_1 [1, 1, 864, 128]
/device:CPU:0 B2_L19/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L19/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L19/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L20/BatchNorm/gamma [896]
/device:CPU:0 B2_L20/BatchNorm/beta [896]
/device:CPU:0 B2_L20/Bottleneck/conv_1 [1, 1, 896, 128]
/device:CPU:0 B2_L20/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L20/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L20/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L21/BatchNorm/gamma [928]
/device:CPU:0 B2_L21/BatchNorm/beta [928]
/device:CPU:0 B2_L21/Bottleneck/conv_1 [1, 1, 928, 128]
/device:CPU:0 B2_L21/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L21/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L21/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L22/BatchNorm/gamma [960]
/device:CPU:0 B2_L22/BatchNorm/beta [960]
/device:CPU:0 B2_L22/Bottleneck/conv_1 [1, 1, 960, 128]
/device:CPU:0 B2_L22/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L22/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L22/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B2_L23/BatchNorm/gamma [992]
/device:CPU:0 B2_L23/BatchNorm/beta [992]
/device:CPU:0 B2_L23/Bottleneck/conv_1 [1, 1, 992, 128]
/device:CPU:0 B2_L23/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B2_L23/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B2_L23/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 T2/BatchNorm/gamma [1024]
/device:CPU:0 T2/BatchNorm/beta [1024]
/device:CPU:0 T2/conv_1 [1, 1, 1024, 512]
/device:CPU:0 B3_L0/BatchNorm/gamma [512]
/device:CPU:0 B3_L0/BatchNorm/beta [512]
/device:CPU:0 B3_L0/Bottleneck/conv_1 [1, 1, 512, 128]
/device:CPU:0 B3_L0/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L0/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L0/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L1/BatchNorm/gamma [544]
/device:CPU:0 B3_L1/BatchNorm/beta [544]
/device:CPU:0 B3_L1/Bottleneck/conv_1 [1, 1, 544, 128]
/device:CPU:0 B3_L1/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L1/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L1/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L2/BatchNorm/gamma [576]
/device:CPU:0 B3_L2/BatchNorm/beta [576]
/device:CPU:0 B3_L2/Bottleneck/conv_1 [1, 1, 576, 128]
/device:CPU:0 B3_L2/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L2/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L2/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L3/BatchNorm/gamma [608]
/device:CPU:0 B3_L3/BatchNorm/beta [608]
/device:CPU:0 B3_L3/Bottleneck/conv_1 [1, 1, 608, 128]
/device:CPU:0 B3_L3/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L3/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L3/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L4/BatchNorm/gamma [640]
/device:CPU:0 B3_L4/BatchNorm/beta [640]
/device:CPU:0 B3_L4/Bottleneck/conv_1 [1, 1, 640, 128]
/device:CPU:0 B3_L4/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L4/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L4/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L5/BatchNorm/gamma [672]
/device:CPU:0 B3_L5/BatchNorm/beta [672]
/device:CPU:0 B3_L5/Bottleneck/conv_1 [1, 1, 672, 128]
/device:CPU:0 B3_L5/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L5/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L5/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L6/BatchNorm/gamma [704]
/device:CPU:0 B3_L6/BatchNorm/beta [704]
/device:CPU:0 B3_L6/Bottleneck/conv_1 [1, 1, 704, 128]
/device:CPU:0 B3_L6/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L6/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L6/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L7/BatchNorm/gamma [736]
/device:CPU:0 B3_L7/BatchNorm/beta [736]
/device:CPU:0 B3_L7/Bottleneck/conv_1 [1, 1, 736, 128]
/device:CPU:0 B3_L7/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L7/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L7/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L8/BatchNorm/gamma [768]
/device:CPU:0 B3_L8/BatchNorm/beta [768]
/device:CPU:0 B3_L8/Bottleneck/conv_1 [1, 1, 768, 128]
/device:CPU:0 B3_L8/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L8/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L8/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L9/BatchNorm/gamma [800]
/device:CPU:0 B3_L9/BatchNorm/beta [800]
/device:CPU:0 B3_L9/Bottleneck/conv_1 [1, 1, 800, 128]
/device:CPU:0 B3_L9/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L9/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L9/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L10/BatchNorm/gamma [832]
/device:CPU:0 B3_L10/BatchNorm/beta [832]
/device:CPU:0 B3_L10/Bottleneck/conv_1 [1, 1, 832, 128]
/device:CPU:0 B3_L10/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L10/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L10/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L11/BatchNorm/gamma [864]
/device:CPU:0 B3_L11/BatchNorm/beta [864]
/device:CPU:0 B3_L11/Bottleneck/conv_1 [1, 1, 864, 128]
/device:CPU:0 B3_L11/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L11/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L11/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L12/BatchNorm/gamma [896]
/device:CPU:0 B3_L12/BatchNorm/beta [896]
/device:CPU:0 B3_L12/Bottleneck/conv_1 [1, 1, 896, 128]
/device:CPU:0 B3_L12/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L12/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L12/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L13/BatchNorm/gamma [928]
/device:CPU:0 B3_L13/BatchNorm/beta [928]
/device:CPU:0 B3_L13/Bottleneck/conv_1 [1, 1, 928, 128]
/device:CPU:0 B3_L13/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L13/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L13/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L14/BatchNorm/gamma [960]
/device:CPU:0 B3_L14/BatchNorm/beta [960]
/device:CPU:0 B3_L14/Bottleneck/conv_1 [1, 1, 960, 128]
/device:CPU:0 B3_L14/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L14/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L14/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 B3_L15/BatchNorm/gamma [992]
/device:CPU:0 B3_L15/BatchNorm/beta [992]
/device:CPU:0 B3_L15/Bottleneck/conv_1 [1, 1, 992, 128]
/device:CPU:0 B3_L15/Bottleneck/BatchNorm/gamma [128]
/device:CPU:0 B3_L15/Bottleneck/BatchNorm/beta [128]
/device:CPU:0 B3_L15/Conv/conv_1 [3, 3, 128, 32]
/device:CPU:0 T3/BatchNorm/gamma [1024]
/device:CPU:0 T3/BatchNorm/beta [1024]
/device:CPU:0 logit/fc_1 [1024, 1000]
Parameters: 7977728 {'conv': 6870208, 'batchnorm': 83520, 'fc': 1024000}
MACs: 2834161664
MEMs: 21842
Training model on GPU 1
Perform input channel normalization in GPU for speed
In the inception_v2 argumentation, image are already scaled to [0,1]
mean = [0.485 0.456 0.406] std = [0.229 0.224 0.225]
Input data format is NHWC, convert to NCHW
DenseNet for ImageNet dataset
Add L2 weight decay 0.0001 to following trainable variables:
['init/conv_1', 'init/batchnorm/gamma', 'init/batchnorm/beta', 'b0_l0/bottleneck/conv_1', 'b0_l0/bottleneck/batchnorm/gamma', 'b0_l0/bottleneck/batchnorm/beta', 'b0_l0/conv/conv_1', 'b0_l1/batchnorm/gamma', 'b0_l1/batchnorm/beta', 'b0_l1/bottleneck/conv_1', 'b0_l1/bottleneck/batchnorm/gamma', 'b0_l1/bottleneck/batchnorm/beta', 'b0_l1/conv/conv_1', 'b0_l2/batchnorm/gamma', 'b0_l2/batchnorm/beta', 'b0_l2/bottleneck/conv_1', 'b0_l2/bottleneck/batchnorm/gamma', 'b0_l2/bottleneck/batchnorm/beta', 'b0_l2/conv/conv_1', 'b0_l3/batchnorm/gamma', 'b0_l3/batchnorm/beta', 'b0_l3/bottleneck/conv_1', 'b0_l3/bottleneck/batchnorm/gamma', 'b0_l3/bottleneck/batchnorm/beta', 'b0_l3/conv/conv_1', 'b0_l4/batchnorm/gamma', 'b0_l4/batchnorm/beta', 'b0_l4/bottleneck/conv_1', 'b0_l4/bottleneck/batchnorm/gamma', 'b0_l4/bottleneck/batchnorm/beta', 'b0_l4/conv/conv_1', 'b0_l5/batchnorm/gamma', 'b0_l5/batchnorm/beta', 'b0_l5/bottleneck/conv_1', 'b0_l5/bottleneck/batchnorm/gamma', 'b0_l5/bottleneck/batchnorm/beta', 'b0_l5/conv/conv_1', 't0/batchnorm/gamma', 't0/batchnorm/beta', 't0/conv_1', 'b1_l0/batchnorm/gamma', 'b1_l0/batchnorm/beta', 'b1_l0/bottleneck/conv_1', 'b1_l0/bottleneck/batchnorm/gamma', 'b1_l0/bottleneck/batchnorm/beta', 'b1_l0/conv/conv_1', 'b1_l1/batchnorm/gamma', 'b1_l1/batchnorm/beta', 'b1_l1/bottleneck/conv_1', 'b1_l1/bottleneck/batchnorm/gamma', 'b1_l1/bottleneck/batchnorm/beta', 'b1_l1/conv/conv_1', 'b1_l2/batchnorm/gamma', 'b1_l2/batchnorm/beta', 'b1_l2/bottleneck/conv_1', 'b1_l2/bottleneck/batchnorm/gamma', 'b1_l2/bottleneck/batchnorm/beta', 'b1_l2/conv/conv_1', 'b1_l3/batchnorm/gamma', 'b1_l3/batchnorm/beta', 'b1_l3/bottleneck/conv_1', 'b1_l3/bottleneck/batchnorm/gamma', 'b1_l3/bottleneck/batchnorm/beta', 'b1_l3/conv/conv_1', 'b1_l4/batchnorm/gamma', 'b1_l4/batchnorm/beta', 'b1_l4/bottleneck/conv_1', 'b1_l4/bottleneck/batchnorm/gamma', 'b1_l4/bottleneck/batchnorm/beta', 'b1_l4/conv/conv_1', 'b1_l5/batchnorm/gamma', 'b1_l5/batchnorm/beta', 'b1_l5/bottleneck/conv_1', 'b1_l5/bottleneck/batchnorm/gamma', 'b1_l5/bottleneck/batchnorm/beta', 'b1_l5/conv/conv_1', 'b1_l6/batchnorm/gamma', 'b1_l6/batchnorm/beta', 'b1_l6/bottleneck/conv_1', 'b1_l6/bottleneck/batchnorm/gamma', 'b1_l6/bottleneck/batchnorm/beta', 'b1_l6/conv/conv_1', 'b1_l7/batchnorm/gamma', 'b1_l7/batchnorm/beta', 'b1_l7/bottleneck/conv_1', 'b1_l7/bottleneck/batchnorm/gamma', 'b1_l7/bottleneck/batchnorm/beta', 'b1_l7/conv/conv_1', 'b1_l8/batchnorm/gamma', 'b1_l8/batchnorm/beta', 'b1_l8/bottleneck/conv_1', 'b1_l8/bottleneck/batchnorm/gamma', 'b1_l8/bottleneck/batchnorm/beta', 'b1_l8/conv/conv_1', 'b1_l9/batchnorm/gamma', 'b1_l9/batchnorm/beta', 'b1_l9/bottleneck/conv_1', 'b1_l9/bottleneck/batchnorm/gamma', 'b1_l9/bottleneck/batchnorm/beta', 'b1_l9/conv/conv_1', 'b1_l10/batchnorm/gamma', 'b1_l10/batchnorm/beta', 'b1_l10/bottleneck/conv_1', 'b1_l10/bottleneck/batchnorm/gamma', 'b1_l10/bottleneck/batchnorm/beta', 'b1_l10/conv/conv_1', 'b1_l11/batchnorm/gamma', 'b1_l11/batchnorm/beta', 'b1_l11/bottleneck/conv_1', 'b1_l11/bottleneck/batchnorm/gamma', 'b1_l11/bottleneck/batchnorm/beta', 'b1_l11/conv/conv_1', 't1/batchnorm/gamma', 't1/batchnorm/beta', 't1/conv_1', 'b2_l0/batchnorm/gamma', 'b2_l0/batchnorm/beta', 'b2_l0/bottleneck/conv_1', 'b2_l0/bottleneck/batchnorm/gamma', 'b2_l0/bottleneck/batchnorm/beta', 'b2_l0/conv/conv_1', 'b2_l1/batchnorm/gamma', 'b2_l1/batchnorm/beta', 'b2_l1/bottleneck/conv_1', 'b2_l1/bottleneck/batchnorm/gamma', 'b2_l1/bottleneck/batchnorm/beta', 'b2_l1/conv/conv_1', 'b2_l2/batchnorm/gamma', 'b2_l2/batchnorm/beta', 'b2_l2/bottleneck/conv_1', 'b2_l2/bottleneck/batchnorm/gamma', 'b2_l2/bottleneck/batchnorm/beta', 'b2_l2/conv/conv_1', 'b2_l3/batchnorm/gamma', 'b2_l3/batchnorm/beta', 'b2_l3/bottleneck/conv_1', 'b2_l3/bottleneck/batchnorm/gamma', 'b2_l3/bottleneck/batchnorm/beta', 'b2_l3/conv/conv_1', 'b2_l4/batchnorm/gamma', 'b2_l4/batchnorm/beta', 'b2_l4/bottleneck/conv_1', 'b2_l4/bottleneck/batchnorm/gamma', 'b2_l4/bottleneck/batchnorm/beta', 'b2_l4/conv/conv_1', 'b2_l5/batchnorm/gamma', 'b2_l5/batchnorm/beta', 'b2_l5/bottleneck/conv_1', 'b2_l5/bottleneck/batchnorm/gamma', 'b2_l5/bottleneck/batchnorm/beta', 'b2_l5/conv/conv_1', 'b2_l6/batchnorm/gamma', 'b2_l6/batchnorm/beta', 'b2_l6/bottleneck/conv_1', 'b2_l6/bottleneck/batchnorm/gamma', 'b2_l6/bottleneck/batchnorm/beta', 'b2_l6/conv/conv_1', 'b2_l7/batchnorm/gamma', 'b2_l7/batchnorm/beta', 'b2_l7/bottleneck/conv_1', 'b2_l7/bottleneck/batchnorm/gamma', 'b2_l7/bottleneck/batchnorm/beta', 'b2_l7/conv/conv_1', 'b2_l8/batchnorm/gamma', 'b2_l8/batchnorm/beta', 'b2_l8/bottleneck/conv_1', 'b2_l8/bottleneck/batchnorm/gamma', 'b2_l8/bottleneck/batchnorm/beta', 'b2_l8/conv/conv_1', 'b2_l9/batchnorm/gamma', 'b2_l9/batchnorm/beta', 'b2_l9/bottleneck/conv_1', 'b2_l9/bottleneck/batchnorm/gamma', 'b2_l9/bottleneck/batchnorm/beta', 'b2_l9/conv/conv_1', 'b2_l10/batchnorm/gamma', 'b2_l10/batchnorm/beta', 'b2_l10/bottleneck/conv_1', 'b2_l10/bottleneck/batchnorm/gamma', 'b2_l10/bottleneck/batchnorm/beta', 'b2_l10/conv/conv_1', 'b2_l11/batchnorm/gamma', 'b2_l11/batchnorm/beta', 'b2_l11/bottleneck/conv_1', 'b2_l11/bottleneck/batchnorm/gamma', 'b2_l11/bottleneck/batchnorm/beta', 'b2_l11/conv/conv_1', 'b2_l12/batchnorm/gamma', 'b2_l12/batchnorm/beta', 'b2_l12/bottleneck/conv_1', 'b2_l12/bottleneck/batchnorm/gamma', 'b2_l12/bottleneck/batchnorm/beta', 'b2_l12/conv/conv_1', 'b2_l13/batchnorm/gamma', 'b2_l13/batchnorm/beta', 'b2_l13/bottleneck/conv_1', 'b2_l13/bottleneck/batchnorm/gamma', 'b2_l13/bottleneck/batchnorm/beta', 'b2_l13/conv/conv_1', 'b2_l14/batchnorm/gamma', 'b2_l14/batchnorm/beta', 'b2_l14/bottleneck/conv_1', 'b2_l14/bottleneck/batchnorm/gamma', 'b2_l14/bottleneck/batchnorm/beta', 'b2_l14/conv/conv_1', 'b2_l15/batchnorm/gamma', 'b2_l15/batchnorm/beta', 'b2_l15/bottleneck/conv_1', 'b2_l15/bottleneck/batchnorm/gamma', 'b2_l15/bottleneck/batchnorm/beta', 'b2_l15/conv/conv_1', 'b2_l16/batchnorm/gamma', 'b2_l16/batchnorm/beta', 'b2_l16/bottleneck/conv_1', 'b2_l16/bottleneck/batchnorm/gamma', 'b2_l16/bottleneck/batchnorm/beta', 'b2_l16/conv/conv_1', 'b2_l17/batchnorm/gamma', 'b2_l17/batchnorm/beta', 'b2_l17/bottleneck/conv_1', 'b2_l17/bottleneck/batchnorm/gamma', 'b2_l17/bottleneck/batchnorm/beta', 'b2_l17/conv/conv_1', 'b2_l18/batchnorm/gamma', 'b2_l18/batchnorm/beta', 'b2_l18/bottleneck/conv_1', 'b2_l18/bottleneck/batchnorm/gamma', 'b2_l18/bottleneck/batchnorm/beta', 'b2_l18/conv/conv_1', 'b2_l19/batchnorm/gamma', 'b2_l19/batchnorm/beta', 'b2_l19/bottleneck/conv_1', 'b2_l19/bottleneck/batchnorm/gamma', 'b2_l19/bottleneck/batchnorm/beta', 'b2_l19/conv/conv_1', 'b2_l20/batchnorm/gamma', 'b2_l20/batchnorm/beta', 'b2_l20/bottleneck/conv_1', 'b2_l20/bottleneck/batchnorm/gamma', 'b2_l20/bottleneck/batchnorm/beta', 'b2_l20/conv/conv_1', 'b2_l21/batchnorm/gamma', 'b2_l21/batchnorm/beta', 'b2_l21/bottleneck/conv_1', 'b2_l21/bottleneck/batchnorm/gamma', 'b2_l21/bottleneck/batchnorm/beta', 'b2_l21/conv/conv_1', 'b2_l22/batchnorm/gamma', 'b2_l22/batchnorm/beta', 'b2_l22/bottleneck/conv_1', 'b2_l22/bottleneck/batchnorm/gamma', 'b2_l22/bottleneck/batchnorm/beta', 'b2_l22/conv/conv_1', 'b2_l23/batchnorm/gamma', 'b2_l23/batchnorm/beta', 'b2_l23/bottleneck/conv_1', 'b2_l23/bottleneck/batchnorm/gamma', 'b2_l23/bottleneck/batchnorm/beta', 'b2_l23/conv/conv_1', 't2/batchnorm/gamma', 't2/batchnorm/beta', 't2/conv_1', 'b3_l0/batchnorm/gamma', 'b3_l0/batchnorm/beta', 'b3_l0/bottleneck/conv_1', 'b3_l0/bottleneck/batchnorm/gamma', 'b3_l0/bottleneck/batchnorm/beta', 'b3_l0/conv/conv_1', 'b3_l1/batchnorm/gamma', 'b3_l1/batchnorm/beta', 'b3_l1/bottleneck/conv_1', 'b3_l1/bottleneck/batchnorm/gamma', 'b3_l1/bottleneck/batchnorm/beta', 'b3_l1/conv/conv_1', 'b3_l2/batchnorm/gamma', 'b3_l2/batchnorm/beta', 'b3_l2/bottleneck/conv_1', 'b3_l2/bottleneck/batchnorm/gamma', 'b3_l2/bottleneck/batchnorm/beta', 'b3_l2/conv/conv_1', 'b3_l3/batchnorm/gamma', 'b3_l3/batchnorm/beta', 'b3_l3/bottleneck/conv_1', 'b3_l3/bottleneck/batchnorm/gamma', 'b3_l3/bottleneck/batchnorm/beta', 'b3_l3/conv/conv_1', 'b3_l4/batchnorm/gamma', 'b3_l4/batchnorm/beta', 'b3_l4/bottleneck/conv_1', 'b3_l4/bottleneck/batchnorm/gamma', 'b3_l4/bottleneck/batchnorm/beta', 'b3_l4/conv/conv_1', 'b3_l5/batchnorm/gamma', 'b3_l5/batchnorm/beta', 'b3_l5/bottleneck/conv_1', 'b3_l5/bottleneck/batchnorm/gamma', 'b3_l5/bottleneck/batchnorm/beta', 'b3_l5/conv/conv_1', 'b3_l6/batchnorm/gamma', 'b3_l6/batchnorm/beta', 'b3_l6/bottleneck/conv_1', 'b3_l6/bottleneck/batchnorm/gamma', 'b3_l6/bottleneck/batchnorm/beta', 'b3_l6/conv/conv_1', 'b3_l7/batchnorm/gamma', 'b3_l7/batchnorm/beta', 'b3_l7/bottleneck/conv_1', 'b3_l7/bottleneck/batchnorm/gamma', 'b3_l7/bottleneck/batchnorm/beta', 'b3_l7/conv/conv_1', 'b3_l8/batchnorm/gamma', 'b3_l8/batchnorm/beta', 'b3_l8/bottleneck/conv_1', 'b3_l8/bottleneck/batchnorm/gamma', 'b3_l8/bottleneck/batchnorm/beta', 'b3_l8/conv/conv_1', 'b3_l9/batchnorm/gamma', 'b3_l9/batchnorm/beta', 'b3_l9/bottleneck/conv_1', 'b3_l9/bottleneck/batchnorm/gamma', 'b3_l9/bottleneck/batchnorm/beta', 'b3_l9/conv/conv_1', 'b3_l10/batchnorm/gamma', 'b3_l10/batchnorm/beta', 'b3_l10/bottleneck/conv_1', 'b3_l10/bottleneck/batchnorm/gamma', 'b3_l10/bottleneck/batchnorm/beta', 'b3_l10/conv/conv_1', 'b3_l11/batchnorm/gamma', 'b3_l11/batchnorm/beta', 'b3_l11/bottleneck/conv_1', 'b3_l11/bottleneck/batchnorm/gamma', 'b3_l11/bottleneck/batchnorm/beta', 'b3_l11/conv/conv_1', 'b3_l12/batchnorm/gamma', 'b3_l12/batchnorm/beta', 'b3_l12/bottleneck/conv_1', 'b3_l12/bottleneck/batchnorm/gamma', 'b3_l12/bottleneck/batchnorm/beta', 'b3_l12/conv/conv_1', 'b3_l13/batchnorm/gamma', 'b3_l13/batchnorm/beta', 'b3_l13/bottleneck/conv_1', 'b3_l13/bottleneck/batchnorm/gamma', 'b3_l13/bottleneck/batchnorm/beta', 'b3_l13/conv/conv_1', 'b3_l14/batchnorm/gamma', 'b3_l14/batchnorm/beta', 'b3_l14/bottleneck/conv_1', 'b3_l14/bottleneck/batchnorm/gamma', 'b3_l14/bottleneck/batchnorm/beta', 'b3_l14/conv/conv_1', 'b3_l15/batchnorm/gamma', 'b3_l15/batchnorm/beta', 'b3_l15/bottleneck/conv_1', 'b3_l15/bottleneck/batchnorm/gamma', 'b3_l15/bottleneck/batchnorm/beta', 'b3_l15/conv/conv_1', 't3/batchnorm/gamma', 't3/batchnorm/beta', 'logit/fc_1']
Training model on GPU 2
Perform input channel normalization in GPU for speed
In the inception_v2 argumentation, image are already scaled to [0,1]
mean = [0.485 0.456 0.406] std = [0.229 0.224 0.225]
Input data format is NHWC, convert to NCHW
DenseNet for ImageNet dataset
Training model on GPU 3
Perform input channel normalization in GPU for speed
In the inception_v2 argumentation, image are already scaled to [0,1]
mean = [0.485 0.456 0.406] std = [0.229 0.224 0.225]
Input data format is NHWC, convert to NCHW
DenseNet for ImageNet dataset
Testing model on GPU 3
Perform input channel normalization in GPU for speed
In the inception_v2 argumentation, image are already scaled to [0,1]
mean = [0.485 0.456 0.406] std = [0.229 0.224 0.225]
Input data format is NHWC, convert to NCHW
DenseNet for ImageNet dataset
----------------------------------------------------------------------------------------------------
Epoch: 001 Loss: 4.893827 Train: 0.8839 Test: 0.7500 lr: 0.1000 FPS: 712 
Epoch: 002 Loss: 3.492907 Train: 0.7207 Test: 0.6277 lr: 0.0999 FPS: 708 B S
Epoch: 003 Loss: 3.038658 Train: 0.6466 Test: 0.5833 lr: 0.0998 FPS: 708 B S
Epoch: 004 Loss: 2.830663 Train: 0.6105 Test: 0.5520 lr: 0.0996 FPS: 709 B S
Epoch: 005 Loss: 2.704466 Train: 0.5883 Test: 0.5300 lr: 0.0994 FPS: 696 B S
Epoch: 006 Loss: 2.623567 Train: 0.5746 Test: 0.5093 lr: 0.0991 FPS: 702 B S
Epoch: 007 Loss: 2.562587 Train: 0.5628 Test: 0.5013 lr: 0.0988 FPS: 696 B S
Epoch: 008 Loss: 2.516523 Train: 0.5542 Test: 0.4969 lr: 0.0984 FPS: 693 B S
Epoch: 009 Loss: 2.482231 Train: 0.5475 Test: 0.4939 lr: 0.0980 FPS: 694 B S
Epoch: 010 Loss: 2.453905 Train: 0.5426 Test: 0.4861 lr: 0.0976 FPS: 702 B S
Epoch: 011 Loss: 2.427471 Train: 0.5378 Test: 0.4776 lr: 0.0970 FPS: 711 B S
Epoch: 012 Loss: 2.405477 Train: 0.5333 Test: 0.4752 lr: 0.0965 FPS: 704 B S
Epoch: 013 Loss: 2.385092 Train: 0.5298 Test: 0.4646 lr: 0.0959 FPS: 709 B S
Epoch: 014 Loss: 2.370299 Train: 0.5277 Test: 0.4702 lr: 0.0952 FPS: 710 
Epoch: 015 Loss: 2.356521 Train: 0.5241 Test: 0.4639 lr: 0.0946 FPS: 704 B S
Epoch: 016 Loss: 2.343578 Train: 0.5217 Test: 0.4570 lr: 0.0938 FPS: 706 B S
Epoch: 017 Loss: 2.333100 Train: 0.5199 Test: 0.4634 lr: 0.0930 FPS: 708 
Epoch: 018 Loss: 2.318563 Train: 0.5172 Test: 0.4480 lr: 0.0922 FPS: 708 B S
Epoch: 019 Loss: 2.308325 Train: 0.5156 Test: 0.4630 lr: 0.0914 FPS: 707 
Epoch: 020 Loss: 2.293958 Train: 0.5130 Test: 0.4467 lr: 0.0905 FPS: 704 B S
Epoch: 021 Loss: 2.293772 Train: 0.5129 Test: 0.4544 lr: 0.0895 FPS: 707 
Epoch: 022 Loss: 2.278739 Train: 0.5099 Test: 0.4447 lr: 0.0885 FPS: 705 B S
Epoch: 023 Loss: 2.267561 Train: 0.5079 Test: 0.4368 lr: 0.0875 FPS: 704 B S
Epoch: 024 Loss: 2.257987 Train: 0.5059 Test: 0.4457 lr: 0.0864 FPS: 709 
Epoch: 025 Loss: 2.243960 Train: 0.5038 Test: 0.4385 lr: 0.0854 FPS: 708 
Epoch: 026 Loss: 2.234270 Train: 0.5017 Test: 0.4377 lr: 0.0842 FPS: 703 
Epoch: 027 Loss: 2.224840 Train: 0.4994 Test: 0.4389 lr: 0.0831 FPS: 707 
Epoch: 028 Loss: 2.212433 Train: 0.4975 Test: 0.4331 lr: 0.0819 FPS: 699 B S
Epoch: 029 Loss: 2.205208 Train: 0.4963 Test: 0.4229 lr: 0.0806 FPS: 702 B S
Epoch: 030 Loss: 2.193359 Train: 0.4940 Test: 0.4295 lr: 0.0794 FPS: 707 
Epoch: 031 Loss: 2.186360 Train: 0.4921 Test: 0.4278 lr: 0.0781 FPS: 704 
Epoch: 032 Loss: 2.175136 Train: 0.4903 Test: 0.4321 lr: 0.0768 FPS: 697 
Epoch: 033 Loss: 2.161820 Train: 0.4882 Test: 0.4232 lr: 0.0755 FPS: 697 
Epoch: 034 Loss: 2.153014 Train: 0.4861 Test: 0.4249 lr: 0.0741 FPS: 702 
Epoch: 035 Loss: 2.138936 Train: 0.4834 Test: 0.4175 lr: 0.0727 FPS: 707 B S
Epoch: 036 Loss: 2.131065 Train: 0.4818 Test: 0.4047 lr: 0.0713 FPS: 699 B S
Epoch: 037 Loss: 2.120200 Train: 0.4805 Test: 0.4149 lr: 0.0699 FPS: 696 
Epoch: 038 Loss: 2.111372 Train: 0.4786 Test: 0.4125 lr: 0.0684 FPS: 699 
Epoch: 039 Loss: 2.097403 Train: 0.4755 Test: 0.4095 lr: 0.0669 FPS: 703 
Epoch: 040 Loss: 2.087390 Train: 0.4737 Test: 0.4111 lr: 0.0655 FPS: 707 
Epoch: 041 Loss: 2.075835 Train: 0.4712 Test: 0.4018 lr: 0.0639 FPS: 701 B S
Epoch: 042 Loss: 2.062508 Train: 0.4689 Test: 0.4001 lr: 0.0624 FPS: 707 B S
Epoch: 043 Loss: 2.051666 Train: 0.4665 Test: 0.3911 lr: 0.0609 FPS: 709 B S
Epoch: 044 Loss: 2.036345 Train: 0.4642 Test: 0.4022 lr: 0.0594 FPS: 706 
Epoch: 045 Loss: 2.023772 Train: 0.4616 Test: 0.3981 lr: 0.0578 FPS: 707 
Epoch: 046 Loss: 2.012899 Train: 0.4590 Test: 0.3961 lr: 0.0563 FPS: 698 
Epoch: 047 Loss: 2.001949 Train: 0.4567 Test: 0.3947 lr: 0.0547 FPS: 710 
Epoch: 048 Loss: 1.988362 Train: 0.4545 Test: 0.3824 lr: 0.0531 FPS: 709 B S
Epoch: 049 Loss: 1.975795 Train: 0.4515 Test: 0.3837 lr: 0.0516 FPS: 706 
Epoch: 050 Loss: 1.959900 Train: 0.4491 Test: 0.3875 lr: 0.0500 FPS: 704 
Epoch: 051 Loss: 1.946618 Train: 0.4464 Test: 0.3770 lr: 0.0484 FPS: 706 B S
Epoch: 052 Loss: 1.932791 Train: 0.4433 Test: 0.3844 lr: 0.0469 FPS: 708 
Epoch: 053 Loss: 1.920223 Train: 0.4411 Test: 0.3749 lr: 0.0453 FPS: 706 B S
Epoch: 054 Loss: 1.906554 Train: 0.4382 Test: 0.3708 lr: 0.0437 FPS: 706 B S
Epoch: 055 Loss: 1.889969 Train: 0.4345 Test: 0.3662 lr: 0.0422 FPS: 705 B S
Epoch: 056 Loss: 1.876539 Train: 0.4321 Test: 0.3692 lr: 0.0406 FPS: 694 
Epoch: 057 Loss: 1.857273 Train: 0.4284 Test: 0.3645 lr: 0.0391 FPS: 705 B S
Epoch: 058 Loss: 1.844028 Train: 0.4265 Test: 0.3629 lr: 0.0376 FPS: 707 B S
Epoch: 059 Loss: 1.828418 Train: 0.4230 Test: 0.3568 lr: 0.0361 FPS: 709 B S
Epoch: 060 Loss: 1.812499 Train: 0.4195 Test: 0.3564 lr: 0.0345 FPS: 703 B S
Epoch: 061 Loss: 1.795850 Train: 0.4158 Test: 0.3553 lr: 0.0331 FPS: 706 B S
Epoch: 062 Loss: 1.781195 Train: 0.4129 Test: 0.3493 lr: 0.0316 FPS: 706 B S
Epoch: 063 Loss: 1.761553 Train: 0.4095 Test: 0.3470 lr: 0.0301 FPS: 699 B S
Epoch: 064 Loss: 1.742973 Train: 0.4054 Test: 0.3428 lr: 0.0287 FPS: 701 B S
Epoch: 065 Loss: 1.726657 Train: 0.4021 Test: 0.3380 lr: 0.0273 FPS: 694 B S
Epoch: 066 Loss: 1.709330 Train: 0.3988 Test: 0.3320 lr: 0.0259 FPS: 703 B S
Epoch: 067 Loss: 1.690693 Train: 0.3946 Test: 0.3300 lr: 0.0245 FPS: 705 B S
Epoch: 068 Loss: 1.671600 Train: 0.3911 Test: 0.3349 lr: 0.0232 FPS: 704 
Epoch: 069 Loss: 1.652225 Train: 0.3868 Test: 0.3277 lr: 0.0219 FPS: 700 B S
Epoch: 070 Loss: 1.634726 Train: 0.3834 Test: 0.3208 lr: 0.0206 FPS: 705 B S
Epoch: 071 Loss: 1.617718 Train: 0.3797 Test: 0.3222 lr: 0.0194 FPS: 703 
Epoch: 072 Loss: 1.593257 Train: 0.3748 Test: 0.3179 lr: 0.0181 FPS: 706 B S
Epoch: 073 Loss: 1.574694 Train: 0.3706 Test: 0.3107 lr: 0.0169 FPS: 703 B S
Epoch: 074 Loss: 1.554371 Train: 0.3665 Test: 0.3109 lr: 0.0158 FPS: 697 
Epoch: 075 Loss: 1.531674 Train: 0.3618 Test: 0.3085 lr: 0.0146 FPS: 684 B S
Epoch: 076 Loss: 1.511705 Train: 0.3577 Test: 0.3045 lr: 0.0136 FPS: 702 B S
Epoch: 077 Loss: 1.490116 Train: 0.3531 Test: 0.3014 lr: 0.0125 FPS: 702 B S
Epoch: 078 Loss: 1.468791 Train: 0.3483 Test: 0.2927 lr: 0.0115 FPS: 706 B S
Epoch: 079 Loss: 1.444874 Train: 0.3434 Test: 0.2913 lr: 0.0105 FPS: 701 B S
Epoch: 080 Loss: 1.421952 Train: 0.3388 Test: 0.2924 lr: 0.0095 FPS: 701 
Epoch: 081 Loss: 1.398927 Train: 0.3338 Test: 0.2846 lr: 0.0086 FPS: 704 B S
Epoch: 082 Loss: 1.374279 Train: 0.3282 Test: 0.2820 lr: 0.0078 FPS: 705 B S
Epoch: 083 Loss: 1.352945 Train: 0.3236 Test: 0.2805 lr: 0.0070 FPS: 701 B S
Epoch: 084 Loss: 1.329479 Train: 0.3188 Test: 0.2781 lr: 0.0062 FPS: 705 B S
Epoch: 085 Loss: 1.305416 Train: 0.3132 Test: 0.2724 lr: 0.0054 FPS: 703 B S
Epoch: 086 Loss: 1.280528 Train: 0.3083 Test: 0.2703 lr: 0.0048 FPS: 704 B S
Epoch: 087 Loss: 1.255797 Train: 0.3024 Test: 0.2670 lr: 0.0041 FPS: 703 B S
Epoch: 088 Loss: 1.230028 Train: 0.2969 Test: 0.2645 lr: 0.0035 FPS: 706 B S
Epoch: 089 Loss: 1.208589 Train: 0.2922 Test: 0.2593 lr: 0.0030 FPS: 706 B S
Epoch: 090 Loss: 1.184926 Train: 0.2866 Test: 0.2567 lr: 0.0024 FPS: 711 B S
Epoch: 091 Loss: 1.163835 Train: 0.2820 Test: 0.2540 lr: 0.0020 FPS: 710 B S
Epoch: 092 Loss: 1.142290 Train: 0.2774 Test: 0.2530 lr: 0.0016 FPS: 708 B S
Epoch: 093 Loss: 1.125751 Train: 0.2736 Test: 0.2508 lr: 0.0012 FPS: 708 B S
Epoch: 094 Loss: 1.107928 Train: 0.2698 Test: 0.2481 lr: 0.0009 FPS: 705 B S
Epoch: 095 Loss: 1.093218 Train: 0.2662 Test: 0.2461 lr: 0.0006 FPS: 706 B S
Epoch: 096 Loss: 1.082263 Train: 0.2639 Test: 0.2461 lr: 0.0004 FPS: 694 B S
Epoch: 097 Loss: 1.072678 Train: 0.2616 Test: 0.2451 lr: 0.0002 FPS: 707 B S
Epoch: 098 Loss: 1.067885 Train: 0.2604 Test: 0.2443 lr: 0.0001 FPS: 700 B S
Epoch: 099 Loss: 1.064508 Train: 0.2598 Test: 0.2442 lr: 0.0000 FPS: 706 B S
----------------------------------------------------------------------------------------------------
Optimization ended at 18-12-13 04:39:19
